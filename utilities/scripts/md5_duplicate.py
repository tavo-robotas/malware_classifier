# Locate and remove duplicate files
# Assuming that MD5 hash is unique for each file
# same MD5 comes from same file but with different name

# Input:
# 1.  Files directory path
# 2.  Output directory path
# 2.1 Directory for storing duplicate copies
# 2.2 Directory for strong .csv [ID, FILENAME, MD5, SIZE]
#
# Output:
# 1.  Clean file (without duplicates) with MD5 and size 
# 2.  Duplicates file


import os
import csv
import shutil
import hashlib

class DuplicateFiles():
    
    def __init__(self, source, output):
        self.source = source
        self.output = output
        # self.destination = destination
        
    @staticmethod
    def get_file_hash(file):
        md5 = hashlib.md5()
        with open(file, 'rb') as f:
            for chunk in iter(lambda: f.read(128* md5.block_size), b''):
                md5.update(chunk)
        return md5.hexdigest()
    
    @staticmethod
    def get_file_size(file):
        return os.stat(file).st_size
        
    @staticmethod
    def write_header(path: str):
        with open(path, 'a') as file:
            writer = csv.writer(file, delimiter=',')
            writer.writerow(['ID', 'NAME', 'MD5', 'SIZE'])
    
    @staticmethod
    def write_data(path: str, data):
        with open(path, 'a') as file:
            writer = csv.writer(file, delimiter=',')
            writer.writerow(data)
        
    
    def get_hash_file_dict(file):
        result = {}
        data = open(file, 'r')
        for line in reader:
            if line in result:
                pass
        
            
    def get_duplicate_files():
        pass
    
    def move_duplicates():
        pass
    
    def write_file(self, outputfile):
        path = self.output + outputfile
        self.write_header(path)
        for idx, item in enumerate(os.listdir(self.source)):
            file = self.source + item
            data = [idx, item, self.get_file_hash(file), self.get_file_size(file)]
            self.write_data(path, data)
            print(f'file: {item} stored')
           
                
    
def main():
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('-s', '--source',   type=str, required=True, help='source files path')
    parser.add_argument('-o', '--output',   type=str, required=True, help='output storage path')
    parser.add_argument('-f', '--filename', type=str, required=True, help='output file name')
    args = parser.parse_args()
    
    source   = args.source
    output   = args.output
    filename = args.filename
    
    print(f'taking files from: {source}')
    print(f'storing files to : {output}')
    print(f'stored in file   : {filename}.csv')
    
    duplicate = DuplicateFiles(source, output)
    duplicate.write_file(f'{filename}.csv')
    
if __name__ == '__main__':
    main()