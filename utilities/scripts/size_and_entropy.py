# Calculate Entroy and Data Size of all files
# present in a given directory
# Assuming that entropy measures can be decent learners/ features


# Input:
# 1.  Files directory path
# 2.  Output directory path
# 2.1 Directory for storing duplicate copies
# 2.2 Directory for strong .csv [ID, FILENAME, MD5, SIZE]
#
# Output:
# 1.  Clean file (without duplicates) with MD5 and size 
# 2.  Duplicates file


import os
import csv
import math
import pefile

class EntropyExtractor():
    
    def __init__(self, source:str, output:str):
        self.source = source,
        self.output = output

    def calculate_entropy(byte_counts, size):
        entropy = 0.0
        for count in byte_counts:
            if count == 0:
                continue
            p = 1.0 * count / size
            entropy -= p * math.log(p, 256)
        return entropy

    def entropy_counter(byte_code, code_length):
        byte_code, code_length = self.get_file_bytes_size(self.source)
        byte_counts = [0] * 256
        for i in range(code_length):
            byte_counts[int(byte_code[i])] +=1
        return calculate_entropy(byte_counts, code_length)

    def get_byte_distribution(byte_arr, size ):
        count = { f'0x{i}':(float(byte_arr.count(i))/size) for i in byte_arr }
        return count

    def get_file_bytes_size(path):    
        with open(path, 'rb') as file:
            byte_arr = file.read()
            size     = len(byte_arr)

        return byte_arr, size

def main():
    source = None
    output = None
    ee = EntropyExtractor(source, output)
    ee.entropy_counter()

if __name__ == '__main__':
    main()
    



file = 'S5sYvWYxyOsNCgpZGOmNNfOUNNu8oeSW.dll'
path = '../../data/0/'
