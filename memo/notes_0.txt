Literature:
https://www.youtube.com/watch?v=HMWulRpPpuA&list=PLonlF40eS6nzc7TqDshRo7k-mTM1Tu_j4&ab_channel=CristiVlad
Machine learning for Malware detection

Mastering Machine Learning for Penetration Testing: Develop abd extensive skill set to break self learning systems using Python

PE Headers of non malware and malware samples 

file formats: .acm, .cpl, .exe, .ocx, .mui, .sys, .dll, .scr, etc.
HEADER   : DOS Header, PE Header, Optional Header, Sections Table
SECTIONS : Code, Imports, Data

PE type format provides information for windows loader on how to manage exectuable code wrapped inside.

DOS Header: To validate the executable and actually run it in the DOS stub
PE Header: with a lot of information such as the location of code in memory, size of the code  
Optional Header: 
Section Table:

Code:
Imports:
Data:

In some PE not all of these sections are present.

PEView, PEExplorer tools to get insight on legitimate windows files and malware samples
Do it in well isolated environment such as virtual machine or a sandbox.


Classifiers: RandomForest, Gradient Boosting Adaboost, etc.


Malware from PE Headers
 - Malware data set: htpps://github.com/
 - 96,724 malware files from virusshare.com
 
 
56 Features to define the executable as a legitimate or malware.

Tree Classifier

from sklearn.ensemble import ExtraTreesClassifier (to optimize our dataset)
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel (to improve accuracy with this)
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn import cross_validation


data_in = malData.drop(['Name', 'md5', 'legitimate'], axis=1).values
labels  = malData['legitimate'].values

extratress = ExtraTressClassifier().fit(data_in, labels)
select = SelectFromModel(extratress, prefit=True)
data_in_new = select.transform(data_in)

print(data_in.shape, data_in_new.shape)

import numpy as np

features = data_in.new.shape(1)
importances = extratress.feature_importances_

indices = np.argsort(imporances)[::-1]
for f in range(features):
    print(f'{f+1}', malData.columns[2+indices[f]], importances[indices[f]])
    
    

legit_train, legit_test, mal_train, mal_test = cross_validation.train_test_split(data_in_new, labels, test_size=.2)

classif = RandomForestClassifier(n_estimators=50) # mean trees in the forest 
classif.fit(legin_train, mal_train)

print(classif.score(legit_test, mal_test)*100)

% when classifier mistakenly classified as being legit when in reality it was malware
false_negatives


result = classif.predict(legit_test)
cm = confusion_matrix(mal_test, result)

print(cm)

array(
    [[19195,   97],
     [72   , 8246]]
)

print(f'false positives: {cm[0][1]/sum(cm[0])*100}')
print(f'false negatives: {cm[1][0]/sum(cm[1])*100}')


# Gradient Boosting

from sklearn.ensemble import GradientBoostingClassifier

grad_boost = GradientBoostingClassifier(n_estimator=50) # to remain consitent
grad_boost.fit(legit_train, mal_train)

print(grad_boost.score(legit_test, mal_test)*100)

