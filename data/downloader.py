from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib import request

base      = 'http://s3-nord-challenge-data.s3-website.eu-central-1.amazonaws.com/'
safe_dir  = '0/'
malw_di   = '1/'
s_list    = 'files_0.txt'
m_list    = 'files_1.txt'

def retrieve_and_save_data(url):
    link = url.split('/')
    sdir = 0 if int(link[3]) == 0 else 1
    name, extension = link[-1].split('.')
    try:
        content = request.urlopen(url).read()
        with open(f'{sdir}/{name}.{extension}', "wb") as outfile:
            outfile.write(content)
            print(f'processed: {name}.{extension}')
    except Exception as ex:
        print(f'error: {ex}')
        
with ThreadPoolExecutor() as exe:
    exe.map(retrieve_and_save_data, (f'{base}{malw_di}{i.rstrip()}' for i in open(m_list).readlines()))
